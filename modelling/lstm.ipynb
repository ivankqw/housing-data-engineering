{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from pprint import pprint\n",
    "import pickle\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# map district name to district number\n",
    "district_mapping_path = \"../airflow/dags/data/districts.xlsx\"\n",
    "\n",
    "district_mapping = pd.read_excel(district_mapping_path)\n",
    "\n",
    "\n",
    "def get_district_name(district_no):\n",
    "    return district_mapping[district_mapping[\"Postal District\"] == district_no][\n",
    "        \"General Location\"\n",
    "    ].values[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import all previous files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open pickle\n",
    "train_df_dict = pd.read_pickle('data/train_df_dict.pkl')\n",
    "train_df_dict_L = pd.read_pickle('data/train_df_dict_L.pkl')\n",
    "test_df_dict = pd.read_pickle('data/test_df_dict.pkl')\n",
    "\n",
    "# import resale_flat_transactions_clean\n",
    "resale_flat_transactions_clean = pd.read_csv('data/resale_flat_transactions_clean.csv')\n",
    "\n",
    "# import features \n",
    "all_district_var_ts = pd.read_pickle('data/all_district_var_ts.pkl')\n",
    "\n",
    "# remove the NaN values from train set\n",
    "# train_df_dict_clean = {}\n",
    "# for district_no, district_df in train_df_dict.items():\n",
    "#     train_df_dict_clean[district_no] = district_df.dropna()\n",
    "\n",
    "# hopefully lstm can handle the NaN values\n",
    "\n",
    "# merge the train set with the features\n",
    "train_lstm_df_dict = {}\n",
    "for district_no, district_df in train_df_dict.items():\n",
    "    train_lstm_df_dict[district_no] = district_df.to_frame().merge(all_district_var_ts[district_no], left_index=True, right_index=True, how='left')\n",
    "\n",
    "train_lstm_df_dict_L = {}\n",
    "for district_no, district_df in train_df_dict_L.items():\n",
    "    train_lstm_df_dict_L[district_no] = district_df.to_frame().merge(all_district_var_ts[district_no], left_index=True, right_index=True, how='left')\n",
    "\n",
    "# merge the test set with the features\n",
    "test_lstm_df_dict = {}\n",
    "for district_no, district_df in test_df_dict.items():\n",
    "    test_lstm_df_dict[district_no] = district_df.to_frame().merge(all_district_var_ts[district_no], left_index=True, right_index=True, how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resale_price</th>\n",
       "      <th>resale_price_std</th>\n",
       "      <th>floor_area_sqm_median</th>\n",
       "      <th>remaining_lease_years_median</th>\n",
       "      <th>max_floor_lvl_median</th>\n",
       "      <th>precinct_pavilion_sum</th>\n",
       "      <th>commercial_sum</th>\n",
       "      <th>market_hawker_sum</th>\n",
       "      <th>miscellaneous_sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month_year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>430000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>61.666667</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01</th>\n",
       "      <td>515000.0</td>\n",
       "      <td>63639.610307</td>\n",
       "      <td>98.5</td>\n",
       "      <td>58.375000</td>\n",
       "      <td>20.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01</th>\n",
       "      <td>420000.0</td>\n",
       "      <td>137790.904393</td>\n",
       "      <td>65.0</td>\n",
       "      <td>64.916667</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-01</th>\n",
       "      <td>447500.0</td>\n",
       "      <td>85559.920524</td>\n",
       "      <td>67.5</td>\n",
       "      <td>58.208333</td>\n",
       "      <td>20.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            resale_price  resale_price_std  floor_area_sqm_median  \\\n",
       "month_year                                                          \n",
       "2018-01-01      430000.0               NaN                   60.0   \n",
       "2018-02-01           NaN               NaN                    NaN   \n",
       "2018-03-01      515000.0      63639.610307                   98.5   \n",
       "2018-04-01      420000.0     137790.904393                   65.0   \n",
       "2018-05-01      447500.0      85559.920524                   67.5   \n",
       "\n",
       "            remaining_lease_years_median  max_floor_lvl_median  \\\n",
       "month_year                                                       \n",
       "2018-01-01                     61.666667                  18.0   \n",
       "2018-02-01                           NaN                   NaN   \n",
       "2018-03-01                     58.375000                  20.5   \n",
       "2018-04-01                     64.916667                  21.0   \n",
       "2018-05-01                     58.208333                  20.5   \n",
       "\n",
       "            precinct_pavilion_sum  commercial_sum  market_hawker_sum  \\\n",
       "month_year                                                             \n",
       "2018-01-01                    0.0             0.0                0.0   \n",
       "2018-02-01                    NaN             NaN                NaN   \n",
       "2018-03-01                    0.0             0.0                0.0   \n",
       "2018-04-01                    0.0             0.0                0.0   \n",
       "2018-05-01                    0.0             0.0                0.0   \n",
       "\n",
       "            miscellaneous_sum  \n",
       "month_year                     \n",
       "2018-01-01                0.0  \n",
       "2018-02-01                NaN  \n",
       "2018-03-01                0.0  \n",
       "2018-04-01                0.0  \n",
       "2018-05-01                0.0  "
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lstm_df_dict[1].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create scalers for each district\n",
    "scaler_dict = {}\n",
    "for district_no, district_df in train_lstm_df_dict.items():\n",
    "    scaler_dict[district_no] = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaler_dict[district_no].fit(district_df)\n",
    "\n",
    "# create scalers for each district\n",
    "scaler_dict_L = {}\n",
    "for district_no, district_df in train_lstm_df_dict_L.items():\n",
    "    scaler_dict_L[district_no] = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaler_dict_L[district_no].fit(district_df)\n",
    "\n",
    "# transform the train set\n",
    "train_lstm_df_dict_scaled = {}\n",
    "for district_no, district_df in train_lstm_df_dict.items():\n",
    "    train_lstm_df_dict_scaled[district_no] = pd.DataFrame(\n",
    "        scaler_dict[district_no].transform(district_df),\n",
    "        columns=district_df.columns,\n",
    "        index=district_df.index,\n",
    "    )\n",
    "\n",
    "# transform the train set\n",
    "train_lstm_df_dict_scaled_L = {}\n",
    "for district_no, district_df in train_lstm_df_dict_L.items():\n",
    "    train_lstm_df_dict_scaled_L[district_no] = pd.DataFrame(\n",
    "        scaler_dict_L[district_no].transform(district_df),\n",
    "        columns=district_df.columns,\n",
    "        index=district_df.index,\n",
    "    )\n",
    "\n",
    "# transform the test set\n",
    "test_lstm_df_dict_scaled = {}\n",
    "for district_no, district_df in test_lstm_df_dict.items():\n",
    "    test_lstm_df_dict_scaled[district_no] = pd.DataFrame(\n",
    "        scaler_dict[district_no].transform(district_df),\n",
    "        columns=district_df.columns,\n",
    "        index=district_df.index,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resale_price</th>\n",
       "      <th>resale_price_std</th>\n",
       "      <th>floor_area_sqm_median</th>\n",
       "      <th>remaining_lease_years_median</th>\n",
       "      <th>max_floor_lvl_median</th>\n",
       "      <th>precinct_pavilion_sum</th>\n",
       "      <th>commercial_sum</th>\n",
       "      <th>market_hawker_sum</th>\n",
       "      <th>miscellaneous_sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month_year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>-0.434276</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.811765</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>-0.217391</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01</th>\n",
       "      <td>0.131448</td>\n",
       "      <td>-0.369697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.207692</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01</th>\n",
       "      <td>-0.500832</td>\n",
       "      <td>0.746614</td>\n",
       "      <td>-0.576471</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-01</th>\n",
       "      <td>-0.317804</td>\n",
       "      <td>-0.039697</td>\n",
       "      <td>-0.458824</td>\n",
       "      <td>-0.238462</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            resale_price  resale_price_std  floor_area_sqm_median  \\\n",
       "month_year                                                          \n",
       "2018-01-01     -0.434276               NaN              -0.811765   \n",
       "2018-02-01           NaN               NaN                    NaN   \n",
       "2018-03-01      0.131448         -0.369697               1.000000   \n",
       "2018-04-01     -0.500832          0.746614              -0.576471   \n",
       "2018-05-01     -0.317804         -0.039697              -0.458824   \n",
       "\n",
       "            remaining_lease_years_median  max_floor_lvl_median  \\\n",
       "month_year                                                       \n",
       "2018-01-01                      0.400000             -0.217391   \n",
       "2018-02-01                           NaN                   NaN   \n",
       "2018-03-01                     -0.207692              0.217391   \n",
       "2018-04-01                      1.000000              0.304348   \n",
       "2018-05-01                     -0.238462              0.217391   \n",
       "\n",
       "            precinct_pavilion_sum  commercial_sum  market_hawker_sum  \\\n",
       "month_year                                                             \n",
       "2018-01-01                   -1.0            -1.0               -1.0   \n",
       "2018-02-01                    NaN             NaN                NaN   \n",
       "2018-03-01                   -1.0            -1.0               -1.0   \n",
       "2018-04-01                   -1.0            -1.0               -1.0   \n",
       "2018-05-01                   -1.0            -1.0               -1.0   \n",
       "\n",
       "            miscellaneous_sum  \n",
       "month_year                     \n",
       "2018-01-01               -1.0  \n",
       "2018-02-01                NaN  \n",
       "2018-03-01               -1.0  \n",
       "2018-04-01               -1.0  \n",
       "2018-05-01               -1.0  "
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lstm_df_dict_scaled[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resale_price</th>\n",
       "      <th>resale_price_std</th>\n",
       "      <th>floor_area_sqm_median</th>\n",
       "      <th>remaining_lease_years_median</th>\n",
       "      <th>max_floor_lvl_median</th>\n",
       "      <th>precinct_pavilion_sum</th>\n",
       "      <th>commercial_sum</th>\n",
       "      <th>market_hawker_sum</th>\n",
       "      <th>miscellaneous_sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month_year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>-0.434276</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.811765</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>-0.217391</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-01</th>\n",
       "      <td>-0.151414</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01</th>\n",
       "      <td>0.131448</td>\n",
       "      <td>-0.369697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.207692</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01</th>\n",
       "      <td>-0.500832</td>\n",
       "      <td>0.746614</td>\n",
       "      <td>-0.576471</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-01</th>\n",
       "      <td>-0.317804</td>\n",
       "      <td>-0.039697</td>\n",
       "      <td>-0.458824</td>\n",
       "      <td>-0.238462</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            resale_price  resale_price_std  floor_area_sqm_median  \\\n",
       "month_year                                                          \n",
       "2018-01-01     -0.434276               NaN              -0.811765   \n",
       "2018-02-01     -0.151414               NaN                    NaN   \n",
       "2018-03-01      0.131448         -0.369697               1.000000   \n",
       "2018-04-01     -0.500832          0.746614              -0.576471   \n",
       "2018-05-01     -0.317804         -0.039697              -0.458824   \n",
       "\n",
       "            remaining_lease_years_median  max_floor_lvl_median  \\\n",
       "month_year                                                       \n",
       "2018-01-01                      0.400000             -0.217391   \n",
       "2018-02-01                           NaN                   NaN   \n",
       "2018-03-01                     -0.207692              0.217391   \n",
       "2018-04-01                      1.000000              0.304348   \n",
       "2018-05-01                     -0.238462              0.217391   \n",
       "\n",
       "            precinct_pavilion_sum  commercial_sum  market_hawker_sum  \\\n",
       "month_year                                                             \n",
       "2018-01-01                   -1.0            -1.0               -1.0   \n",
       "2018-02-01                    NaN             NaN                NaN   \n",
       "2018-03-01                   -1.0            -1.0               -1.0   \n",
       "2018-04-01                   -1.0            -1.0               -1.0   \n",
       "2018-05-01                   -1.0            -1.0               -1.0   \n",
       "\n",
       "            miscellaneous_sum  \n",
       "month_year                     \n",
       "2018-01-01               -1.0  \n",
       "2018-02-01                NaN  \n",
       "2018-03-01               -1.0  \n",
       "2018-04-01               -1.0  \n",
       "2018-05-01               -1.0  "
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lstm_df_dict_scaled_L[1].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare input and output for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for LSTM\n",
    "\n",
    "# seq consists of the features and previous observations N through T where T-N is the lookback period\n",
    "# lookback period is 12 months\n",
    "\n",
    "# target consists of the observations T+1 through T+K where K is the number of steps ahead to predict (lookahead period)\n",
    "# lookahead period is 3 months\n",
    "\n",
    "# create a special dataset for LSTM\n",
    "def create_dataset(X, Y, target_col, look_back):\n",
    "    # dataX, dataY = [], []\n",
    "    seqs = []\n",
    "    for i in range(len(X)-look_back-2):\n",
    "        curr_seq = (X[i:(i + look_back)])\n",
    "        # dataY.append(Y[(i + look_back):(i + look_back)])\n",
    "        # label = Y.iloc[(i + look_back): (i+ look_back + 3)][target_col].values\n",
    "        # label = Y.iloc[(i + look_back): (i+ look_back + 3)][target_col].values.reshape(1, -1)\n",
    "        label = Y.iloc[(i + look_back): (i+ look_back + 1)][target_col].values.reshape(1, -1)\n",
    "        seqs.append((curr_seq, label))\n",
    "    return seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lstm_seqs = {}\n",
    "for district_no, district_df in train_lstm_df_dict_scaled.items():\n",
    "    train_lstm_seqs[district_no] = create_dataset(district_df, district_df, 'resale_price', 12)\n",
    "\n",
    "train_lstm_seqs_L = {}\n",
    "for district_no, district_df in train_lstm_df_dict_scaled_L.items():\n",
    "    train_lstm_seqs_L[district_no] = create_dataset(district_df, district_df, 'resale_price', 12)\n",
    "\n",
    "test_lstm_seqs = {}\n",
    "for district_no, district_df in test_lstm_df_dict_scaled.items():\n",
    "    test_lstm_seqs[district_no] = create_dataset(district_df, district_df, 'resale_price', 12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 39\n"
     ]
    }
   ],
   "source": [
    "print(len(train_lstm_seqs[1]), (len(train_lstm_df_dict_scaled[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_lstm_df_dict_scaled[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 9)\n"
     ]
    }
   ],
   "source": [
    "print(train_lstm_seqs[1][0][0].shape) # 12 time steps lookback, 9 features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_lstm_seqs[1][0][1].shape) # 3 steps ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "print(len(train_lstm_seqs[1])) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriceDataset(Dataset):\n",
    "    def __init__(self, seqs):\n",
    "        self.seqs = seqs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seqs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq, label = self.seqs[idx]\n",
    "        return dict(\n",
    "            seq=torch.tensor(seq.to_numpy(), dtype=torch.float),\n",
    "            label=torch.tensor(label[-3:], dtype=torch.float)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriceDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, train_seqs, test_seqs, batch_size=8):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.train_seqs = train_seqs\n",
    "        self.test_seqs = test_seqs\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = PriceDataset(self.train_seqs)\n",
    "        self.test_dataset = PriceDataset(self.test_seqs)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=0.2)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.lstm.flatten_parameters() \n",
    "        # init hidden state\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).requires_grad_()\n",
    "        # init cell state \n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).requires_grad_()\n",
    "        # detach hidden state and cell state from the graph to prevent backpropagation\n",
    "        out, _ = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "        # keep the last 3 time step of each sequence in the batch to predict the next 3 time steps\n",
    "        out = self.fc(out[:, -1:, :])\n",
    "        print(out.shape)\n",
    "        return out\n",
    "\n",
    "class LSTMTrainer(pl.LightningModule):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, learning_rate):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = LSTM(input_size, hidden_size, num_layers, output_size)\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        seq, label = batch[\"seq\"], batch[\"label\"]\n",
    "        # pass the sequence through the model\n",
    "        out = self.model(seq)\n",
    "        # reshape output to match the shape of the label\n",
    "        out = out.view(out.size(0), 1, -1)\n",
    "        loss = torch.sqrt(F.mse_loss(out, label))\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        seq, label = batch[\"seq\"], batch[\"label\"]\n",
    "        out = self.model(seq)\n",
    "        # reshape output to match the shape of the label\n",
    "        out = out.view(out.size(0), 1, -1)\n",
    "        # loss function RMSE \n",
    "        # compute the RMSE of the last time step of each sequence in the batch where the label is the next 3 time steps\n",
    "        loss = torch.sqrt(F.mse_loss(out, label))\n",
    "        self.log(\"val_loss\", loss)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        seq, label = batch[\"seq\"], batch[\"label\"]\n",
    "        out = self.model(seq)\n",
    "        # reshape output to match the shape of the label\n",
    "        out = out.view(out.size(0), 1, -1)\n",
    "        # loss function RMSE \n",
    "        # compute the RMSE of the last time step of each sequence in the batch where the label is the next 3 time steps\n",
    "        loss = torch.sqrt(F.mse_loss(out, label))\n",
    "        self.log(\"test_loss\", loss)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence Shape:  torch.Size([12, 9])\n",
      "Label: tensor([[-0.0682]]) and Label Shape: torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 64\n",
    "BATCH_SIZE = 8\n",
    "INPUT_SIZE = 9\n",
    "HIDDEN_SIZE = 128\n",
    "NUM_LAYERS = 2\n",
    "OUTPUT_SIZE = 1\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# initialize data module\n",
    "data_module = PriceDataModule(train_lstm_seqs[1], test_lstm_seqs[1], batch_size=BATCH_SIZE)\n",
    "data_module.setup()\n",
    "\n",
    "train_dataset = PriceDataset(train_lstm_seqs[1])\n",
    "\n",
    "# sanity check\n",
    "a = iter(train_dataset)\n",
    "b = next(a)\n",
    "print(\"Sequence Shape: \", b[\"seq\"].shape)\n",
    "print(\"Label: {} and Label Shape: {}\".format(b[\"label\"], b[\"label\"].shape))\n",
    "\n",
    "# initialize the model\n",
    "model = LSTMTrainer(input_size=INPUT_SIZE, hidden_size=HIDDEN_SIZE, num_layers=NUM_LAYERS, output_size=OUTPUT_SIZE, learning_rate=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = b[\"seq\"].shape[1]\n",
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/dataengineering/lib/python3.10/site-packages/pytorch_lightning/trainer/setup.py:201: UserWarning: MPS available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='mps', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/dataengineering/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:108: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | LSTM | 203 K \n",
      "-------------------------------\n",
      "203 K     Trainable params\n",
      "0         Non-trainable params\n",
      "203 K     Total params\n",
      "0.814     Total estimated model params size (MB)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/dataengineering/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/dataengineering/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3affe2fbc9514e279122a6620c98f824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=64` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([8, 1, 1])\n",
      "torch.Size([1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# initialize the trainer\n",
    "trainer = pl.Trainer(max_epochs=N_EPOCHS)\n",
    "\n",
    "# start training\n",
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "trainer.save_checkpoint(\"models/lstm_model_1.ckpt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMTrainer.load_from_checkpoint(\"models/lstm_model_1.ckpt\",\n",
    "                                         input_size=INPUT_SIZE,\n",
    "                                         hidden_size=HIDDEN_SIZE,\n",
    "                                         num_layers=NUM_LAYERS,\n",
    "                                         output_size=OUTPUT_SIZE,\n",
    "                                         learning_rate=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([1, 1, 1])\n",
      "torch.Size([1, 1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[[nan]]], dtype=float32),\n",
       " array([[[nan]]], dtype=float32),\n",
       " array([[[nan]]], dtype=float32),\n",
       " array([[[nan]]], dtype=float32),\n",
       " array([[[nan]]], dtype=float32),\n",
       " array([[[nan]]], dtype=float32),\n",
       " array([[[nan]]], dtype=float32),\n",
       " array([[[nan]]], dtype=float32),\n",
       " array([[[nan]]], dtype=float32),\n",
       " array([[[nan]]], dtype=float32)]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the model to make predictions on the test set\n",
    "test_dataset = PriceDataset(test_lstm_seqs[1])\n",
    "predictions = []\n",
    "labels = []\n",
    "\n",
    "for i in range(len(test_dataset)):\n",
    "    seq, label = test_dataset[i][\"seq\"], test_dataset[i][\"label\"]\n",
    "    out = model.model(seq.unsqueeze(0))\n",
    "    predictions.append(out.detach().numpy())\n",
    "    labels.append(label.detach().numpy())\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 24)"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions), len(test_lstm_df_dict_scaled[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_lstm_df_dict_scaled[1]) - 12"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverse Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descale(scaler, data):\n",
    "    return scaler.inverse_transform(data)\n",
    "\n",
    "def plot_predictions(predictions, labels, scaler, ticker):\n",
    "    predictions = descale(scaler, predictions)\n",
    "    labels = descale(scaler, labels)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(predictions, label=\"Predictions\")\n",
    "    plt.plot(labels, label=\"Labels\")\n",
    "    plt.title(f\"Predictions vs Labels for {ticker}\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 4. None expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/ivankoh/personal/housing-data-engineering/modelling/lstm.ipynb Cell 34\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ivankoh/personal/housing-data-engineering/modelling/lstm.ipynb#Y100sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m plot_predictions(predictions, labels, scaler_dict[\u001b[39m1\u001b[39;49m], \u001b[39m\"\u001b[39;49m\u001b[39mTest\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32m/Users/ivankoh/personal/housing-data-engineering/modelling/lstm.ipynb Cell 34\u001b[0m in \u001b[0;36mplot_predictions\u001b[0;34m(predictions, labels, scaler, ticker)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ivankoh/personal/housing-data-engineering/modelling/lstm.ipynb#Y100sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot_predictions\u001b[39m(predictions, labels, scaler, ticker):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ivankoh/personal/housing-data-engineering/modelling/lstm.ipynb#Y100sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     predictions \u001b[39m=\u001b[39m descale(scaler, predictions)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ivankoh/personal/housing-data-engineering/modelling/lstm.ipynb#Y100sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     labels \u001b[39m=\u001b[39m descale(scaler, labels)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ivankoh/personal/housing-data-engineering/modelling/lstm.ipynb#Y100sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m12\u001b[39m, \u001b[39m6\u001b[39m))\n",
      "\u001b[1;32m/Users/ivankoh/personal/housing-data-engineering/modelling/lstm.ipynb Cell 34\u001b[0m in \u001b[0;36mdescale\u001b[0;34m(scaler, data)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ivankoh/personal/housing-data-engineering/modelling/lstm.ipynb#Y100sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdescale\u001b[39m(scaler, data):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ivankoh/personal/housing-data-engineering/modelling/lstm.ipynb#Y100sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m scaler\u001b[39m.\u001b[39;49minverse_transform(data)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dataengineering/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:528\u001b[0m, in \u001b[0;36mMinMaxScaler.inverse_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Undo the scaling of X according to feature_range.\u001b[39;00m\n\u001b[1;32m    515\u001b[0m \n\u001b[1;32m    516\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[39m    Transformed data.\u001b[39;00m\n\u001b[1;32m    525\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    526\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 528\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m    529\u001b[0m     X, copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy, dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES, force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m    530\u001b[0m )\n\u001b[1;32m    532\u001b[0m X \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_\n\u001b[1;32m    533\u001b[0m X \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscale_\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dataengineering/lib/python3.10/site-packages/sklearn/utils/validation.py:893\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    888\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    889\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    890\u001b[0m     )\n\u001b[1;32m    892\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nd \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[0;32m--> 893\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    894\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    895\u001b[0m         \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    896\u001b[0m     )\n\u001b[1;32m    898\u001b[0m \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[1;32m    899\u001b[0m     _assert_all_finite(\n\u001b[1;32m    900\u001b[0m         array,\n\u001b[1;32m    901\u001b[0m         input_name\u001b[39m=\u001b[39minput_name,\n\u001b[1;32m    902\u001b[0m         estimator_name\u001b[39m=\u001b[39mestimator_name,\n\u001b[1;32m    903\u001b[0m         allow_nan\u001b[39m=\u001b[39mforce_all_finite \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mallow-nan\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    904\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with dim 4. None expected <= 2."
     ]
    }
   ],
   "source": [
    "plot_predictions(predictions, labels, scaler_dict[1], \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataengineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
