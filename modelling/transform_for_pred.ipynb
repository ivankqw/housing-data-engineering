{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import time\n",
    "from pprint import pprint\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_transactions_df = pd.read_csv(\"data/resale_flat_transactions_clean.csv\")\n",
    "\n",
    "# map district name to district number\n",
    "district_mapping_path = \"../airflow/dags/data/districts.xlsx\"\n",
    "\n",
    "district_mapping = pd.read_excel(district_mapping_path)\n",
    "\n",
    "\n",
    "def get_district_name(district_no):\n",
    "    return district_mapping[district_mapping[\"Postal District\"] == district_no][\n",
    "        \"General Location\"\n",
    "    ].values[0]\n",
    "\n",
    "# cpi \n",
    "cpi_df = pd.read_csv(\"data/cpi.csv\")\n",
    "# convert cpi month to datetime\n",
    "cpi_df[\"Month\"] = pd.to_datetime(cpi_df[\"Month\"], format=\"%Y-%m\")\n",
    "# rename value to cpi\n",
    "cpi_df = cpi_df.rename(columns={\"Value\": \"cpi\"})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering for all data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## helper func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ts_per_district(grouped):\n",
    "    # get a ts for each district\n",
    "    districts = grouped[\"district\"].unique()\n",
    "    all_district_var_ts = {}\n",
    "    for district in districts:\n",
    "        all_district_var_ts[district] = grouped[\n",
    "            grouped[\"district\"] == district\n",
    "        ].set_index(\"month_year\")\n",
    "\n",
    "        # create missing months (months with no transactions will be filled with NaN)\n",
    "        # for each year except current year, check if all months are present\n",
    "        years = all_district_var_ts[district].index.year.unique()\n",
    "        years = years[years != time.localtime().tm_year]\n",
    "        # if not, create missing months and fill with NaN\n",
    "        for year in years:\n",
    "            months = all_district_var_ts[district].loc[str(year)].index.month.unique()\n",
    "            if len(months) < 12:\n",
    "                missing_months = set(range(1, 13)) - set(months)\n",
    "                for month in missing_months:\n",
    "                    all_district_var_ts[district].loc[\n",
    "                        pd.to_datetime(f\"{year}-{month}-01\")\n",
    "                    ] = np.nan\n",
    "        # missing months for current year up to current month\n",
    "        curr_year_months = all_district_var_ts[district].loc[str(time.localtime().tm_year)].index.month.unique()\n",
    "        if len(curr_year_months) < time.localtime().tm_mon:\n",
    "            missing_months = set(range(1, time.localtime().tm_mon)) - set(curr_year_months)\n",
    "            for month in missing_months:\n",
    "                all_district_var_ts[district].loc[\n",
    "                    pd.to_datetime(f\"{time.localtime().tm_year}-{month}-01\")\n",
    "                ] = np.nan\n",
    "        # sort by month_year\n",
    "        all_district_var_ts[district] = all_district_var_ts[district].sort_index()\n",
    "\n",
    "    # # flatten multiindex columns\n",
    "    # for district_no, district_df in all_district_var_ts.items():\n",
    "    #     district_df.columns = [f\"{x}_{y}\" for x, y in district_df.columns.to_flat_index()]\n",
    "\n",
    "    # remove district_ column\n",
    "    for district_no, district_df in all_district_var_ts.items():\n",
    "        all_district_var_ts[district_no] = all_district_var_ts[district_no].drop(\n",
    "            \"district\", axis=1\n",
    "        )\n",
    "    return all_district_var_ts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resale Transactions (from eda_resale_transactions.ipynb and sarima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "resale_flat_transactions = pd.read_csv(\"data/resale_flats_transformed.csv\")\n",
    "hdb_info = pd.read_csv(\"data/hdb_information.csv\")\n",
    "look_back = 5  # remove after pulling from airflow\n",
    "resale_flat_transactions = resale_flat_transactions[\n",
    "    resale_flat_transactions[\"year\"] >= 2023 - look_back\n",
    "]\n",
    "# create primary key for resale flat transactions and hdb information\n",
    "resale_flat_transactions[\"full_address\"] = (\n",
    "    resale_flat_transactions[\"block\"] + \" \" + resale_flat_transactions[\"street_name\"]\n",
    ")\n",
    "hdb_info[\"full_address\"] = hdb_info[\"blk_no\"] + \" \" + hdb_info[\"street\"]\n",
    "\n",
    "# join the resale flat transactions with the hdb information\n",
    "resale_flat_transactions_new = resale_flat_transactions.merge(\n",
    "    hdb_info, on=\"full_address\", how=\"left\"\n",
    ")\n",
    "# drop NIL\n",
    "resale_flat_transactions_new = resale_flat_transactions_new[\n",
    "    resale_flat_transactions[\"district\"] != \"NIL\"\n",
    "]\n",
    "# convert district to int\n",
    "resale_flat_transactions_new[\"district\"] = resale_flat_transactions_new[\n",
    "    \"district\"\n",
    "].astype(int)\n",
    "# remove unnecessary columns\n",
    "# like duplicated columns after merge\n",
    "# like aggregated columns that leak information about the future\n",
    "to_remove = [\n",
    "    \"street_name\",  # duplicated\n",
    "    \"x\",  # duplicated\n",
    "    \"y\",  # duplicated\n",
    "    \"street_name_with_block\",  # duplicated\n",
    "    \"blk_no\",  # duplicated\n",
    "    \"bldg_contract_town\",  # duplicated (but not exactly) - town\n",
    "    \"_id_y\",  # not needed\n",
    "    \"_id_x\",  # not needed\n",
    "    \"_id_y\",  # not needed\n",
    "    \"exec_sold\",  # leaky\n",
    "    \"1room_rental\",  # leaky\n",
    "    \"1room_sold\",  # leaky\n",
    "    \"2room_rental\",  # leaky\n",
    "    \"2room_sold\",  # leaky\n",
    "    \"3room_rental\",  # leaky\n",
    "    \"3room_sold\",  # leaky\n",
    "    \"4room_sold\",  # leaky\n",
    "    \"5room_sold\",  # leaky\n",
    "    \"multigen_sold\",  # leaky\n",
    "    \"studio_apartment_sold\",  # leaky\n",
    "    \"other_room_rental\",  # leaky\n",
    "]\n",
    "resale_flat_transactions_new = resale_flat_transactions_new.drop(to_remove, axis=1)\n",
    "resale_flat_transactions_new = resale_flat_transactions_new.drop(\"residential\", axis=1)\n",
    "# remove year_completed \n",
    "resale_flat_transactions_new = resale_flat_transactions_new.drop('year_completed', axis=1)\n",
    "# remove lease_commence_date\n",
    "resale_flat_transactions_new = resale_flat_transactions_new.drop('lease_commence_date', axis=1)\n",
    "\n",
    "def get_remaining_lease(row):\n",
    "    a = row['remaining_lease']\n",
    "    year = a.split(' ')[0]\n",
    "    if len(a.split(' ')) < 3:\n",
    "        return int(year)\n",
    "    month = a.split(' ')[2]\n",
    "    return int(year) + int(month)/12\n",
    "\n",
    "# aggregate resale flat transactions by district and time (month and year)\n",
    "resale_flat_transactions_new[\"month_year\"] = (\n",
    "    resale_flat_transactions_new[\"month\"].astype(str)\n",
    "    + \"-\"\n",
    "    + resale_flat_transactions_new[\"year\"].astype(str)\n",
    ")\n",
    "resale_flat_transactions_new[\"month_year\"] = pd.to_datetime(\n",
    "    resale_flat_transactions_new[\"month_year\"], format=\"%m-%Y\"\n",
    ")  # assume first day of month for illustration purposes\n",
    "resale_flat_transactions_new = resale_flat_transactions_new.drop(\n",
    "    [\"month\", \"year\"], axis=1\n",
    ")\n",
    "\n",
    "# convert cpi month to datetime\n",
    "cpi_df[\"Month\"] = pd.to_datetime(cpi_df[\"Month\"], format=\"%Y-%m\")\n",
    "# rename value to cpi\n",
    "cpi_df = cpi_df.rename(columns={\"Value\": \"cpi\"})\n",
    "\n",
    "# merge with cpi\n",
    "resale_flat_transactions_new = pd.merge(\n",
    "    resale_flat_transactions_new,\n",
    "    cpi_df,\n",
    "    how=\"left\",\n",
    "    left_on=\"month_year\",\n",
    "    right_on=\"Month\",\n",
    ")\n",
    "\n",
    "# if cpi is null, fill with previous value\n",
    "# sort resale_flat_transactions_clean by month_year\n",
    "resale_flat_transactions_new = resale_flat_transactions_new.sort_values(\n",
    "    by=\"month_year\"\n",
    ")\n",
    "resale_flat_transactions_new[\"cpi\"] = resale_flat_transactions_new[\"cpi\"].fillna(\n",
    "    method=\"ffill\"\n",
    ")\n",
    "\n",
    "# drop Month column\n",
    "resale_flat_transactions_new = resale_flat_transactions_new.drop([\"Month\"], axis=1)\n",
    "# convert to binary variable\n",
    "resale_flat_transactions_new[\"precinct_pavilion\"] = resale_flat_transactions_new[\n",
    "    \"precinct_pavilion\"\n",
    "].apply(lambda x: 1 if x == \"Y\" else 0)\n",
    "resale_flat_transactions_new[\"commercial\"] = resale_flat_transactions_new[\n",
    "    \"commercial\"\n",
    "].apply(lambda x: 1 if x == \"Y\" else 0)\n",
    "resale_flat_transactions_new[\"market_hawker\"] = resale_flat_transactions_new[\n",
    "    \"market_hawker\"\n",
    "].apply(lambda x: 1 if x == \"Y\" else 0)\n",
    "resale_flat_transactions_new[\"miscellaneous\"] = resale_flat_transactions_new[\n",
    "    \"miscellaneous\"\n",
    "].apply(lambda x: 1 if x == \"Y\" else 0)\n",
    "\n",
    "# convert remaining lease to years\n",
    "resale_flat_transactions_new[\"remaining_lease_years\"] = resale_flat_transactions_new.apply(\n",
    "    get_remaining_lease, axis=1\n",
    ")\n",
    "\n",
    "# perform some basic feature engineering\n",
    "# potential features to include: distance from mrt station, distance from CBD, economic factors like MoM GDP growth, unemployment rate, etc, housing sentiment \n",
    "resale_flat_transactions_df_grouped = resale_flat_transactions_new.groupby([\"district\", \"month_year\"]).agg(\n",
    "    {\n",
    "        \"resale_price\": \"std\",\n",
    "        \"floor_area_sqm\": \"median\",\n",
    "        \"remaining_lease_years\": \"median\",\n",
    "        \"max_floor_lvl\": \"median\",\n",
    "        \"precinct_pavilion\": \"sum\",\n",
    "        \"commercial\": \"sum\",\n",
    "        \"market_hawker\": \"sum\",\n",
    "        \"miscellaneous\": \"sum\",\n",
    "        \"cpi\": \"first\", # cpi is the same for all transactions in a month\n",
    "    }\n",
    ").fillna(0).reset_index() # fillna(0) to fill NaN values with 0\n",
    "\n",
    "resale_flat_transactions_df_grouped_dict = get_ts_per_district(resale_flat_transactions_df_grouped)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## flat rental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['monthly_rent', 'district', 'month_year', 'cpi', 'flat_type_2-ROOM',\n",
      "       'flat_type_3-ROOM', 'flat_type_4-ROOM', 'flat_type_5-ROOM',\n",
      "       'flat_type_EXECUTIVE'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# since based on the results from modelling, linear interpolation does not work well, we will not use it here\n",
    "\n",
    "# in some cases SARIMAX does outperform SARIMA and baseline, so we need to do feature engineering to add features in as exogenous variables\n",
    "\n",
    "# transformations already applied to flat_transactions_df so skip that\n",
    "\n",
    "# flat_rental_df\n",
    "flat_rental_df = pd.read_csv(\"data/flat_rental_transformed.csv\")\n",
    "# take year and month column and convert to datetime\n",
    "flat_rental_df[\"month\"] = flat_rental_df[\"month\"].astype(str)\n",
    "flat_rental_df[\"year\"] = flat_rental_df[\"year\"].astype(str)\n",
    "flat_rental_df[\"month_year\"] = flat_rental_df[\"year\"] + \"-\" + flat_rental_df[\"month\"]\n",
    "# convert month_year to datetime\n",
    "flat_rental_df[\"month_year\"] = pd.to_datetime(\n",
    "    flat_rental_df[\"month_year\"], format=\"%Y-%m\"\n",
    ")\n",
    "# drop year and month columns\n",
    "flat_rental_df = flat_rental_df.drop(columns=[\"year\", \"month\"])\n",
    "# merge with cpi\n",
    "flat_rental_df = flat_rental_df.merge(\n",
    "    cpi_df, how=\"left\", left_on=\"month_year\", right_on=\"Month\"\n",
    ")\n",
    "# sort by month_year\n",
    "flat_rental_df = flat_rental_df.sort_values(by=\"month_year\")\n",
    "# ffill cpi for missing values\n",
    "flat_rental_df[\"cpi\"] = flat_rental_df[\"cpi\"].fillna(method=\"ffill\")\n",
    "# drop Month column\n",
    "flat_rental_df = flat_rental_df.drop(columns=[\"Month\"])\n",
    "# drop other irrelavant columns\n",
    "flat_rental_df = flat_rental_df.drop(\n",
    "    columns=[\n",
    "        \"town\",\n",
    "        \"street_name\",\n",
    "        \"_id\",\n",
    "        \"block\",\n",
    "        \"street_name_with_block\",\n",
    "        \"x\",\n",
    "        \"y\",\n",
    "        \"lat\",\n",
    "        \"lon\",\n",
    "        \"postal\",\n",
    "    ]\n",
    ")\n",
    "# convert flat_type to dummy variables\n",
    "flat_rental_df = pd.get_dummies(\n",
    "    flat_rental_df, columns=[\"flat_type\"], drop_first=True\n",
    ")  # prevent multicollinearity\n",
    "\n",
    "print(flat_rental_df.columns)\n",
    "# group\n",
    "flat_rental_df_grouped = flat_rental_df.groupby([\"district\", \"month_year\"]).agg(\n",
    "    {\n",
    "        \"cpi\": \"first\",\n",
    "        \"flat_type_2-ROOM\": \"sum\",\n",
    "        \"flat_type_3-ROOM\": \"sum\",\n",
    "        \"flat_type_4-ROOM\": \"sum\",\n",
    "        \"flat_type_5-ROOM\": \"sum\",\n",
    "        \"flat_type_EXECUTIVE\": \"sum\",\n",
    "        \"monthly_rent\": \"std\",\n",
    "    }\n",
    ").fillna(0).reset_index()\n",
    "\n",
    "flat_rental_df_grouped_dict = get_ts_per_district(flat_rental_df_grouped)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## private transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['area', 'noOfUnits', 'contractDate', 'price', 'district', 'month_year',\n",
      "       'cpi', 'typeOfArea_Strata', 'propertyType_Condominium',\n",
      "       'propertyType_Detached', 'propertyType_Executive Condominium',\n",
      "       'propertyType_Semi-detached', 'propertyType_Strata Detached',\n",
      "       'propertyType_Strata Semi-detached', 'propertyType_Strata Terrace',\n",
      "       'propertyType_Terrace', 'typeOfSale_2', 'typeOfSale_3',\n",
      "       'marketSegment_OCR', 'marketSegment_RCR', 'is_freehold'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "private_transactions_df = pd.read_csv(\"data/private_transactions_transformed.csv\")\n",
    "private_transactions_df = private_transactions_df.drop(\n",
    "    columns=[\n",
    "    \"floorRange\",\n",
    "    \"nettPrice\", \n",
    "    \"street\",\n",
    "    \"project\"\n",
    "    ]\n",
    ")\n",
    "private_transactions_df[\"month\"] = private_transactions_df[\"month\"].astype(str)\n",
    "private_transactions_df[\"year\"] = private_transactions_df[\"year\"].astype(str)\n",
    "private_transactions_df[\"month_year\"] = private_transactions_df[\"year\"] + \"-\" + private_transactions_df[\"month\"]\n",
    "private_transactions_df[\"month_year\"] = pd.to_datetime(\n",
    "    private_transactions_df[\"month_year\"], format=\"%Y-%m\"\n",
    ")\n",
    "private_transactions_df = private_transactions_df.drop(columns=[\"year\", \"month\"])\n",
    "private_transactions_df = private_transactions_df.merge(\n",
    "    cpi_df, how=\"left\", left_on=\"month_year\", right_on=\"Month\"\n",
    ")\n",
    "private_transactions_df = private_transactions_df.sort_values(by=\"month_year\")\n",
    "private_transactions_df[\"cpi\"] = private_transactions_df[\"cpi\"].fillna(method=\"ffill\")\n",
    "private_transactions_df = private_transactions_df.drop(columns=[\"Month\"])\n",
    "# convert tenure to dummy variables\n",
    "# private_transactions_df = pd.get_dummies(\n",
    "#     private_transactions_df, columns=[\"tenure\"], drop_first=True\n",
    "# )  # prevent multicollinearity\n",
    "# convert typeOfArea to dummy variables\n",
    "private_transactions_df = pd.get_dummies(\n",
    "    private_transactions_df, columns=[\"typeOfArea\"], drop_first=True\n",
    ")  # prevent multicollinearity\n",
    "# convert propertyType to dummy variables\n",
    "private_transactions_df = pd.get_dummies(\n",
    "    private_transactions_df, columns=[\"propertyType\"], drop_first=True\n",
    ")  # prevent multicollinearity\n",
    "# convert typeOfSale to dummy variables\n",
    "private_transactions_df = pd.get_dummies(\n",
    "    private_transactions_df, columns=[\"typeOfSale\"], drop_first=True\n",
    ")  # prevent multicollinearity\n",
    "# convert marketSegment to dummy variables\n",
    "private_transactions_df = pd.get_dummies(\n",
    "    private_transactions_df, columns=[\"marketSegment\"], drop_first=True\n",
    ")  # prevent multicollinearity\n",
    "# transform tenure into a binary variable whether freehold or not \n",
    "private_transactions_df['is_freehold'] = private_transactions_df['tenure'].apply(lambda x: 1 if x == 'Freehold' else 0)\n",
    "private_transactions_df.drop(columns=['tenure'], inplace=True)\n",
    "# group by district and month_year\n",
    "print(private_transactions_df.columns)\n",
    "private_transactions_df_grouped = private_transactions_df.groupby([\"district\", \"month_year\"]).agg(\n",
    "    {\n",
    "        \"cpi\": \"first\",\n",
    "        \"area\": \"median\",\n",
    "        \"noOfUnits\": \"sum\",\n",
    "        \"is_freehold\": \"sum\",\n",
    "        \"typeOfArea_Strata\": \"sum\",\n",
    "        \"propertyType_Condominium\": \"sum\",\n",
    "        \"propertyType_Detached\": \"sum\",\n",
    "        \"propertyType_Executive Condominium\": \"sum\",\n",
    "        \"propertyType_Semi-detached\": \"sum\",\n",
    "        \"propertyType_Strata Semi-detached\": \"sum\",\n",
    "        \"propertyType_Strata Detached\": \"sum\",\n",
    "        \"propertyType_Strata Terrace\": \"sum\",\n",
    "        \"propertyType_Terrace\": \"sum\",\n",
    "        \"typeOfSale_2\": \"sum\",\n",
    "        \"typeOfSale_3\": \"sum\",\n",
    "        \"marketSegment_OCR\": \"sum\",\n",
    "        \"marketSegment_RCR\": \"sum\",\n",
    "        \"is_freehold\": \"sum\",\n",
    "    }\n",
    ").fillna(0).reset_index()\n",
    "\n",
    "private_transactions_df_grouped_dict = get_ts_per_district(private_transactions_df_grouped)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## private rental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['areaSqm', 'leaseDate', 'propertyType', 'district', 'areaSqft',\n",
      "       'noOfBedRoom', 'rent', 'street', 'project', 'month', 'year'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "private_rental_df = pd.read_csv(\"data/private_rental_transformed.csv\")\n",
    "print(private_rental_df.columns)\n",
    "private_rental_df = private_rental_df.drop(\n",
    "    columns=[\n",
    "    \"street\",\n",
    "    \"project\"\n",
    "    ]\n",
    ")\n",
    "# convert areaSqft to dummy variables\n",
    "private_rental_df = pd.get_dummies(\n",
    "    private_rental_df, columns=[\"areaSqft\"], drop_first=True\n",
    ")  # prevent multicollinearity\n",
    "private_rental_df = pd.get_dummies(\n",
    "    private_rental_df, columns=[\"areaSqm\"], drop_first=True\n",
    ")  # prevent multicollinearity\n",
    "private_rental_df = pd.get_dummies(\n",
    "    private_rental_df, columns=[\"propertyType\"], drop_first=True\n",
    ")  # prevent multicollinearity\n",
    "private_rental_df['month'] = private_rental_df['month'].astype(str)\n",
    "private_rental_df['year'] = private_rental_df['year'].astype(str)\n",
    "private_rental_df['month_year'] = private_rental_df['year'] + '-' + private_rental_df['month']\n",
    "private_rental_df['month_year'] = pd.to_datetime(private_rental_df['month_year'], format='%Y-%m')\n",
    "private_rental_df = private_rental_df.drop(columns=['year', 'month', 'leaseDate'])\n",
    "private_rental_df = private_rental_df.merge(cpi_df, how='left', left_on='month_year', right_on='Month')\n",
    "private_rental_df = private_rental_df.sort_values(by='month_year')\n",
    "private_rental_df['cpi'] = private_rental_df['cpi'].fillna(method='ffill')\n",
    "private_rental_df = private_rental_df.drop(columns=['Month'])\n",
    "# create dict for columns to group by\n",
    "agg_dict = {}\n",
    "for col in private_rental_df.columns:\n",
    "    if 'areaSqft' in col:\n",
    "        agg_dict[col] = 'sum'\n",
    "    elif 'areaSqm' in col:\n",
    "        agg_dict[col] = 'sum'\n",
    "    elif 'propertyType' in col:\n",
    "        agg_dict[col] = 'sum'\n",
    "agg_dict['cpi'] = 'first'\n",
    "agg_dict['rent'] = 'median'\n",
    "# group by district and month_year\n",
    "private_rental_df_grouped = private_rental_df.groupby(['district', 'month_year']).agg(agg_dict).fillna(0).reset_index()\n",
    "\n",
    "private_rental_df_grouped_dict = get_ts_per_district(private_rental_df_grouped)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/resale_flat_transactions_df_grouped_dict.pkl\", \"wb\") as f:\n",
    "    pickle.dump(resale_flat_transactions_df_grouped_dict, f)\n",
    "\n",
    "with open(\"data/private_rental_df_grouped_dict.pkl\", \"wb\") as f:\n",
    "    pickle.dump(private_rental_df_grouped_dict, f)\n",
    "\n",
    "with open(\"data/private_transactions_df_grouped_dict.pkl\", \"wb\") as f:\n",
    "    pickle.dump(private_transactions_df_grouped_dict, f)\n",
    "\n",
    "with open(\"data/flat_rental_df_grouped_dict.pkl\", \"wb\") as f:\n",
    "    pickle.dump(flat_rental_df_grouped_dict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataengineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "871a80c3b50ccd6d741e6b8e114b9865acd127a724949f5211d4a3e2b77aebef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
